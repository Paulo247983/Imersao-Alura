{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Paulo247983/Imersao-Alura/blob/main/Imers%C3%A3o_IA_Alura_%2B_Google_Gemini_Agentes_(Projeto).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip -q install google-genai"
      ],
      "metadata": {
        "id": "UCCbECexLk_h"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura a API Key do Google Gemini\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "NfCqHo1tLk8P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura o cliente da SDK do Gemini\n",
        "\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "MODEL_ID = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "bV4w0H5TLk5g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar Framework de agentes do Google ################################################\n",
        "!pip install -q google-adk"
      ],
      "metadata": {
        "id": "a1eRPalxEnj7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a134352e-998e-4d7d-cf4e-207682d2047a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.1/232.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/95.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/217.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.1/217.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/334.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.1/334.1 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.1/125.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aePV2bdfDeoW"
      },
      "outputs": [],
      "source": [
        "# Importações do ADK e outras\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.tools import google_search\n",
        "from google.genai import types as adk_types # <<< ESTA É A IMPORTAÇÃO CRUCIAL PARA ADK.TYPES\n",
        "from datetime import date\n",
        "import textwrap # Para formatar melhor a saída de texto\n",
        "from IPython.display import display, Markdown # Para exibir texto formatado no Colab\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "MODEL_ID = \"gemini-2.0-flash\" # Modelo mais recente e capaz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função auxiliar que envia uma mensagem para um agente via Runner e retorna a resposta final\n",
        "def call_agent(agent: Agent, message_text: str) -> str:\n",
        "    session_service = InMemorySessionService()\n",
        "    session = session_service.create_session(app_name=agent.name, user_id=\"alura_user\", session_id=\"simoc_session\")\n",
        "    runner = Runner(agent=agent, app_name=agent.name, session_service=session_service)\n",
        "    # Aqui usamos o adk_types que deve estar definido agora\n",
        "    content = adk_types.Content(role=\"user\", parts=[adk_types.Part(text=message_text)])\n",
        "\n",
        "    final_response = \"\"\n",
        "    # Itera assincronamente pelos eventos retornados durante a execução do agente\n",
        "    for event in runner.run(user_id=\"alura_user\", session_id=\"simoc_session\", new_message=content):\n",
        "        if event.is_final_response():\n",
        "          for part in event.content.parts:\n",
        "            if part.text is not None:\n",
        "              final_response += part.text\n",
        "              final_response += \"\\n\"\n",
        "    return final_response\n",
        "\n",
        "# Função auxiliar para exibir texto formatado em Markdown no Colab\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "_xP4lWhsS5ko"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função auxiliar para exibir texto formatado em Markdown no Colab\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "8dosiodaxfFR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# --- Agente 1: Agente Estrategista de Configuração (AEC) --- #\n",
        "############################################################\n",
        "def agente_estrategista_configuracao(ideia_foco_inicial: str, data_de_hoje: str):\n",
        "    # Define a instância do agente com o nome 'estrategista_config'\n",
        "    estrategista_config = Agent(\n",
        "        name=\"agente_estrategista_configuracao\",\n",
        "        model=MODEL_ID,\n",
        "        instruction=f\"\"\"\n",
        "        Você é o Agente Estrategista de Configuração (AEC) do Sistema Alura de Monitoramento e Otimização de Conteúdo (SIMOC).\n",
        "        A sua tarefa é ajudar o usuário a definir o 'Foco do Monitoramento' e 'Parâmetros Adicionais'.\n",
        "        O usuário fornecerá uma ideia inicial para o foco.\n",
        "        Use a ferramenta google_search para:\n",
        "        1. Verificar a relevância atual da ideia inicial do usuário (ex: há discussões recentes, notícias, volume de busca?).\n",
        "        2. Sugerir 2-3 termos ou tópicos relacionados que poderiam refinar ou complementar o foco inicial, baseando-se no que é popular ou emergente.\n",
        "        3. Apresente um breve resumo da relevância e as sugestões.\n",
        "        4. Com base nisso, formule uma proposta concisa para o 'Foco do Monitoramento' e peça ao usuário para confirmar ou refinar quaisquer 'Parâmetros Adicionais' (como período específico ou tipos de conteúdo).\n",
        "\n",
        "        Exemplo de saída esperada:\n",
        "        \"Com base na sua ideia de 'cursos de Python', vejo que continua sendo um tópico altamente relevante com muitas buscas recentes por 'Python para análise de dados' e 'Web scraping com Python'.\n",
        "        Sugestões para refinar o foco:\n",
        "        1. Focar em 'Python para análise de dados e IA'.\n",
        "        2. Monitorar especificamente 'novos frameworks Python para web'.\n",
        "\n",
        "        Proposta de Foco do Monitoramento: [Sua proposta aqui baseada na análise]\n",
        "        Quais seriam os Parâmetros Adicionais (ex: 'últimos 30 dias', 'comentários em blogs e fóruns')?\"\n",
        "\n",
        "        Data de hoje para referência de atualidade: {data_de_hoje}.\n",
        "        \"\"\",\n",
        "        description=\"Agente que auxilia estrategicamente o usuário a definir o foco e a configuração do monitoramento usando busca.\",\n",
        "        tools=[google_search]\n",
        "    )\n",
        "\n",
        "    prompt_configuracao = f\"Ideia inicial do usuário para o foco do monitoramento: '{ideia_foco_inicial}'\\nPor favor, ajude a refinar e propor a configuração.\"\n",
        "\n",
        "    # CORREÇÃO: Usa a variável correta 'estrategista_config' ao chamar call_agent\n",
        "    configuracao_sugerida_pelo_agente = call_agent(estrategista_config, prompt_configuracao)\n",
        "\n",
        "    # Exibe a sugestão do agente e pede confirmação/refinamento final ao usuário\n",
        "    print(\"\\n--- ⚙️ Sugestão do Agente Estrategista de Configuração (AEC) ---\")\n",
        "    display(to_markdown(configuracao_sugerida_pelo_agente))\n",
        "\n",
        "    foco_final = input(\"\\nConfirme ou ajuste o 'Foco do Monitoramento' proposto acima: \")\n",
        "    parametros_finais = input(\"Confirme ou defina os 'Parâmetros Adicionais': \")\n",
        "\n",
        "    if not foco_final.strip(): # Adicionado .strip()\n",
        "        # Retorna None para configuração se o foco não for definido, e uma mensagem de erro.\n",
        "        return None, \"Foco do monitoramento não definido pelo usuário após sugestão do AEC.\"\n",
        "\n",
        "    configuracao_final_usuario = f\"Foco do Monitoramento: {foco_final}\\nParâmetros Adicionais: {parametros_finais}\"\n",
        "    print(f\"\\nConfiguração final definida pelo usuário:\\n{configuracao_final_usuario}\")\n",
        "    # Retorna a configuração final e None para o erro (indicando sucesso nesta etapa).\n",
        "    return configuracao_final_usuario, None"
      ],
      "metadata": {
        "id": "o8bqIfi_DyH8"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################################################################\n",
        "# --- Agente 2: Agente Coletor de Dados de Conteúdo (ACDC) --- #\n",
        "###################################################################\n",
        "def agente_coletor_dados(configuracao_monitoramento: str, data_de_hoje: str):\n",
        "    coletor = Agent(\n",
        "        name=\"agente_coletor_dados\",\n",
        "        model=MODEL_ID,\n",
        "        instruction=f\"\"\"\n",
        "        Você é o Agente Coletor de Dados de Conteúdo (ACDC) da Alura.\n",
        "        Sua tarefa é, com base na configuração de monitoramento fornecida, usar a ferramenta de busca do Google (google_search)\n",
        "        para simular a coleta de dados relevantes sobre o conteúdo da Alura.\n",
        "        Busque por menções públicas, discussões em fóruns (se indexados), notícias, ou posts em redes sociais (se publicamente visíveis e indexados)\n",
        "        relacionados ao foco do monitoramento.\n",
        "        Colete informações como:\n",
        "        - Títulos de conteúdo da Alura mencionados.\n",
        "        - Resumo de discussões ou comentários encontrados.\n",
        "        - Possíveis indicadores de engajamento (ex: \"muitos comentários em...\", \"artigo bem compartilhado...\").\n",
        "        - Sentimento geral (se puder ser inferido de forma básica).\n",
        "        - Fontes das informações (URLs).\n",
        "        Retorne um resumo dos dados coletados, no máximo 5-7 pontos chave.\n",
        "        Data de hoje para referência: {data_de_hoje}.\n",
        "        \"\"\",\n",
        "        description=\"Agente que simula a coleta de dados de engajamento e menções ao conteúdo Alura.\",\n",
        "        tools=[google_search]\n",
        "    )\n",
        "\n",
        "    prompt_coleta = f\"Configuração de Monitoramento:\\n{configuracao_monitoramento}\\n\\nPor favor, colete os dados conforme instruído.\"\n",
        "    dados_coletados = call_agent(coletor, prompt_coleta)\n",
        "    return dados_coletados"
      ],
      "metadata": {
        "id": "y3VO1uo5_ghO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################################################\n",
        "# --- Agente 3: Agente Analista de Insights e Tendências (AAIT) --- #\n",
        "#########################################################################\n",
        "def agente_analista_insights(dados_coletados: str, configuracao_monitoramento: str):\n",
        "    analista = Agent(\n",
        "        name=\"agente_analista_insights\",\n",
        "        model=MODEL_ID,\n",
        "        instruction=f\"\"\"\n",
        "        Você é o Agente Analista de Insights e Tendências (AAIT) da Alura.\n",
        "        Com base nos dados coletados pelo ACDC e na configuração original do monitoramento, sua tarefa é:\n",
        "        1. Analisar os dados para identificar padrões, pontos de destaque (positivos ou negativos), e possíveis tendências.\n",
        "        2. Identificar anomalias ou informações críticas (ex: um grande número de reclamações sobre um aspecto específico, ou um conteúdo inesperadamente viral).\n",
        "        3. Inferir insights acionáveis (ex: \"O tópico X está gerando muito interesse\", \"O conteúdo Y parece ter um problema de clareza no ponto Z\", \"Há uma oportunidade para um novo conteúdo sobre W\").\n",
        "        4. Priorizar os 3-4 insights ou decisões mais importantes para a Alura.\n",
        "        Seja conciso e direto ao ponto.\n",
        "        Configuração original do monitoramento para contexto:\n",
        "        {configuracao_monitoramento}\n",
        "        \"\"\",\n",
        "        description=\"Agente que analisa dados de conteúdo e extrai insights e tendências para a Alura.\",\n",
        "        tools=[] # Pode usar google_search para validar/aprofundar alguma tendência se necessário.\n",
        "    )\n",
        "\n",
        "    prompt_analise = f\"Dados Coletados pelo ACDC:\\n{dados_coletados}\\n\\nPor favor, analise estes dados e forneça os insights e decisões conforme instruído.\"\n",
        "    insights_e_decisoes = call_agent(analista, prompt_analise)\n",
        "    return insights_e_decisoes"
      ],
      "metadata": {
        "id": "uOqlg2TRLVh1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################################################\n",
        "# --- Agente 4: Agente Recomendador de Ações Estratégicas (ARAE) --- #\n",
        "#################################################################################\n",
        "def agente_recomendador_acoes(insights_e_decisoes: str, configuracao_monitoramento: str):\n",
        "    recomendador = Agent(\n",
        "        name=\"agente_recomendador_acoes\",\n",
        "        model=MODEL_ID,\n",
        "        instruction=f\"\"\"\n",
        "        Você é o Agente Recomendador de Ações Estratégicas (ARAE) da Alura.\n",
        "        Com base nos insights e decisões fornecidos pelo AAIT, sua tarefa é:\n",
        "        1. Formular 2-3 recomendações de ações estratégicas claras, específicas e acionáveis para as equipes de Conteúdo e Marketing da Alura.\n",
        "        2. As recomendações podem incluir:\n",
        "            - Sugestões de criação ou atualização de conteúdo.\n",
        "            - Ideias para posts em redes sociais ou blog.\n",
        "            - Alertas para revisão de material específico.\n",
        "            - Oportunidades de promoção de conteúdo existente.\n",
        "        3. Justifique brevemente cada recomendação com base nos insights recebidos.\n",
        "        Lembre-se que o objetivo é otimizar o conteúdo da Alura.\n",
        "        Configuração original do monitoramento para contexto:\n",
        "        {configuracao_monitoramento}\n",
        "        \"\"\",\n",
        "        description=\"Agente que propõe ações estratégicas para otimizar o conteúdo da Alura.\"\n",
        "    )\n",
        "\n",
        "    prompt_recomendacao = f\"Insights e Decisões do AAIT:\\n{insights_e_decisoes}\\n\\nPor favor, formule as recomendações de ações estratégicas.\"\n",
        "    recomendacoes = call_agent(recomendador, prompt_recomendacao)\n",
        "    return recomendacoes"
      ],
      "metadata": {
        "id": "_aTb1SdkLeT6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Fluxo Principal do Sistema SIMOC ---\n",
        "def rodar_simoc():\n",
        "    data_hoje = date.today().strftime(\"%d/%m/%Y\")\n",
        "    # Não imprima a mensagem inicial aqui, faremos isso fora do loop se necessário\n",
        "    # print(f\"🚀 Iniciando o Sistema Alura de Monitoramento e Otimização de Conteúdo (SIMOC) - {data_hoje} 🚀\")\n",
        "    # print(\"=\"*70)\n",
        "\n",
        "    # Agente 1: Estrategista de Configuração\n",
        "    print(\"--- 🚀 Agente Estrategista de Configuração (AEC) ---\")\n",
        "    ideia_inicial_usuario = input(\"Olá! Sou o AEC. Qual sua ideia inicial para o foco do monitoramento de conteúdo hoje? \\n(Ex: 'cursos de Python', 'IA Generativa', 'engajamento no Instagram'): \")\n",
        "\n",
        "    if not ideia_inicial_usuario.strip():\n",
        "        print(\"\\n❌ Ideia inicial para o foco não fornecida. Encerrando esta execução.\")\n",
        "        return False # Indica que esta execução falhou na configuração\n",
        "\n",
        "    configuracao, erro_aec = agente_estrategista_configuracao(ideia_inicial_usuario, data_hoje)\n",
        "\n",
        "    if erro_aec:\n",
        "        print(f\"\\n❌ Erro no AEC: {erro_aec}. Encerrando esta execução.\")\n",
        "        return False # Indica falha\n",
        "\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Agente 2: Coleta de Dados\n",
        "    print(\"\\n--- 📊 Agente Coletor de Dados de Conteúdo (ACDC) em ação... ---\")\n",
        "    dados_brutos = agente_coletor_dados(configuracao, data_hoje)\n",
        "    if not dados_brutos.strip():\n",
        "        print(\"\\n❌ ACDC não retornou dados. Verifique a configuração ou a busca. Encerrando esta execução.\")\n",
        "        return False # Indica falha\n",
        "    display(to_markdown(f\"**Dados Brutos Coletados pelo ACDC:**\\n{dados_brutos}\"))\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Agente 3: Análise de Insights\n",
        "    print(\"\\n--- 💡 Agente Analista de Insights e Tendências (AAIT) em ação... ---\")\n",
        "    analise_insights = agente_analista_insights(dados_brutos, configuracao)\n",
        "    if not analise_insights.strip():\n",
        "        print(\"\\n❌ AAIT não retornou análise. Verifique os dados de entrada. Encerrando esta execução.\")\n",
        "        return False # Indica falha\n",
        "    display(to_markdown(f\"**Análise e Insights do AAIT:**\\n{analise_insights}\"))\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Agente 4: Recomendação de Ações\n",
        "    print(\"\\n--- 🎯 Agente Recomendador de Ações Estratégicas (ARAE) em ação... ---\")\n",
        "    acoes_recomendadas = agente_recomendador_acoes(analise_insights, configuracao)\n",
        "    if not acoes_recomendadas.strip():\n",
        "        print(\"\\n❌ ARAE não retornou recomendações. Verifique a análise de entrada. Encerrando esta execução.\")\n",
        "        return False # Indica falha\n",
        "    display(to_markdown(f\"**Ações Estratégicas Recomendadas pelo ARAE:**\\n{acoes_recomendadas}\"))\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\n🎉 Processo SIMOC concluído! 🎉\")\n",
        "    return True # Indica que esta execução foi bem-sucedida\n",
        "\n",
        "# Executar o sistema\n",
        "if __name__ == \"__main__\":\n",
        "    primeira_execucao = True\n",
        "    while True:\n",
        "        if primeira_execucao:\n",
        "            data_hoje_inicial = date.today().strftime(\"%d/%m/%Y\")\n",
        "            print(f\"🚀 Bem-vindo ao Sistema Alura de Monitoramento e Otimização de Conteúdo (SIMOC) - {data_hoje_inicial} 🚀\")\n",
        "            print(\"=\"*70)\n",
        "            primeira_execucao = False\n",
        "        else:\n",
        "            print(\"\\n🔄 Reiniciando o processo SIMOC... 🔄\")\n",
        "            print(\"=\"*70)\n",
        "\n",
        "        sucesso_execucao = rodar_simoc() # Chama a função principal\n",
        "\n",
        "        if not sucesso_execucao:\n",
        "            print(\"\\nA execução anterior encontrou um problema.\")\n",
        "\n",
        "        print(\"-\" * 70) # Separador entre execuções\n",
        "        resposta = input(\"Deseja rodar o processo SIMOC novamente? (s/n): \").strip().lower()\n",
        "        if resposta != 's':\n",
        "            print(\"\\n👋 Encerrando o sistema SIMOC. Até logo!\")\n",
        "            break"
     
}
